{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:5\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:5\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_translation.dataset import ParallelLanguageDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r\"/home/alex/data/nlp/agmir/transf_processed_data\"\n",
    "#data_path = 'transformer_translation/data/processed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = 2000\n",
    "max_seq_length = 96\n",
    "dataset = ParallelLanguageDataset(\n",
    "    os.path.join(data_path, 'tags/set.pkl')#'en/train.pkl')#\n",
    "    ,os.path.join(data_path, 'reports/set.pkl')#'fr/train.pkl')#\n",
    "    ,num_tokens\n",
    "    ,max_seq_length)\n",
    "loader = DataLoader(dataset, batch_size=1, shuffle=True, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_translation.model import LanguageTransformer\n",
    "\n",
    "from einops import rearrange\n",
    "def gen_nopeek_mask(length):\n",
    "    mask = rearrange(torch.triu(torch.ones(length, length)) == 1, 'h w -> w h')\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000 + 4\n",
    "d_model = 512\n",
    "nhead = 8\n",
    "num_encoder_layers = 6\n",
    "num_decoder_layers = 6\n",
    "dim_feedforward = 2048\n",
    "pos_dropout = 0.1\n",
    "trans_dropout = 0.1\n",
    "\n",
    "model = LanguageTransformer(\n",
    "    vocab_size, d_model, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward,\n",
    "    max_seq_length, pos_dropout, trans_dropout\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "    from transformer_translation.Optim import ScheduledOptim\n",
    "    import torch.nn as nn\n",
    "    from torch.optim import Adam\n",
    "    \n",
    "    for p in model.parameters():\n",
    "        if p.dim() > 1:\n",
    "            nn.init.xavier_normal_(p)\n",
    "\n",
    "    n_warmup_steps = 4000\n",
    "    optim = ScheduledOptim(\n",
    "        Adam(model.parameters(), betas=(0.9, 0.98), eps=1e-09),\n",
    "        d_model, n_warmup_steps)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1 / 2] \t Step [10 / 92] \t Train Loss: 9.223678493499756\n",
      "Epoch [1 / 2] \t Step [20 / 92] \t Train Loss: 9.07329568862915\n",
      "Epoch [1 / 2] \t Step [30 / 92] \t Train Loss: 8.81158094406128\n",
      "Epoch [1 / 2] \t Step [40 / 92] \t Train Loss: 8.494706916809083\n",
      "Epoch [1 / 2] \t Step [50 / 92] \t Train Loss: 8.2903902053833\n",
      "Epoch [1 / 2] \t Step [60 / 92] \t Train Loss: 8.098780965805053\n",
      "Epoch [1 / 2] \t Step [70 / 92] \t Train Loss: 7.920980644226074\n",
      "Epoch [1 / 2] \t Step [80 / 92] \t Train Loss: 7.8710309028625485\n",
      "Epoch [1 / 2] \t Step [90 / 92] \t Train Loss: 7.702437925338745\n",
      "Epoch [2 / 2] \t Step [10 / 92] \t Train Loss: 7.611214828491211\n",
      "Epoch [2 / 2] \t Step [20 / 92] \t Train Loss: 7.4070210456848145\n",
      "Epoch [2 / 2] \t Step [30 / 92] \t Train Loss: 7.286341428756714\n",
      "Epoch [2 / 2] \t Step [40 / 92] \t Train Loss: 7.071765279769897\n",
      "Epoch [2 / 2] \t Step [50 / 92] \t Train Loss: 6.956470012664795\n",
      "Epoch [2 / 2] \t Step [60 / 92] \t Train Loss: 6.735355424880981\n",
      "Epoch [2 / 2] \t Step [70 / 92] \t Train Loss: 6.500895071029663\n",
      "Epoch [2 / 2] \t Step [80 / 92] \t Train Loss: 6.474328422546387\n",
      "Epoch [2 / 2] \t Step [90 / 92] \t Train Loss: 6.313019800186157\n",
      "CPU times: user 15min 56s, sys: 35.6 s, total: 16min 32s\n",
      "Wall time: 23.4 s\n"
     ]
    }
   ],
   "source": [
    "    %%time\n",
    "    print_every = 15\n",
    "    num_epochs = 2\n",
    "    model.train()\n",
    "\n",
    "    lowest_val = 1e9\n",
    "    val_losses = []\n",
    "    total_step = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        total_loss = 0\n",
    "\n",
    "        for step, (src, src_key_padding_mask, tgt, tgt_key_padding_mask) in enumerate(iter(loader)):\n",
    "            total_step += 1\n",
    "\n",
    "            src, src_key_padding_mask = src[0].to(device), src_key_padding_mask[0].to(device)\n",
    "            tgt, tgt_key_padding_mask = tgt[0].to(device), tgt_key_padding_mask[0].to(device)\n",
    "\n",
    "            memory_key_padding_mask = src_key_padding_mask.clone()\n",
    "            tgt_inp, tgt_out = tgt[:, :-1], tgt[:, 1:]\n",
    "            tgt_mask = gen_nopeek_mask(tgt_inp.shape[1]).to(device)\n",
    "\n",
    "            optim.zero_grad()\n",
    "            outputs = model(src, tgt_inp, src_key_padding_mask, tgt_key_padding_mask[:, :-1], memory_key_padding_mask, tgt_mask)\n",
    "            loss = criterion(rearrange(outputs, 'b t v -> (b t) v'), rearrange(tgt_out, 'b o -> (b o)'))\n",
    "\n",
    "            loss.backward()\n",
    "            optim.step_and_update_lr()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            if step % print_every == print_every - 1:\n",
    "                print(f'Epoch [{epoch + 1} / {num_epochs}] \\t Step [{step + 1} / {len(loader)}] \\t '\n",
    "                      f'Train Loss: {total_loss / print_every}')\n",
    "                total_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3580"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.data_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 27, 3]),\n",
       " torch.Size([1, 27, 3]),\n",
       " torch.Size([1, 27, 67]),\n",
       " torch.Size([1, 27, 67]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src.shape, src_key_padding_mask.shape, tgt.shape, tgt_key_padding_mask.shape\n",
    "#src_key_padding_mask, tgt, tgt_key_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 30, 3]), torch.Size([1, 30, 95]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(src, src_key_padding_mask, tgt, tgt_key_padding_mask) = next(iter(loader))\n",
    "src.shape, tgt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
