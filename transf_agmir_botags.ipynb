{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_translation.dataset import TagReportDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r\"/home/alex/data/nlp/agmir/transf_processed_data\"\n",
    "#data_path = 'transformer_translation/data/processed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = 2000\n",
    "max_seq_length = 96\n",
    "dataset = TagReportDataset(\n",
    "    os.path.join(data_path, 'tags/set_raw.pkl')\n",
    "    ,os.path.join(data_path, 'reports/set.pkl')\n",
    "    ,num_tokens\n",
    "    ,max_seq_length)\n",
    "loader = DataLoader(dataset, batch_size=1, shuffle=True, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_translation.model import LanguageTransformer, ReportTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000 + 4#1952#\n",
    "nhead = 8\n",
    "d_model = 587 - (587 % nhead) + nhead\n",
    "num_encoder_layers = 6\n",
    "num_decoder_layers = 6\n",
    "dim_feedforward = 2048\n",
    "pos_dropout = 0.1\n",
    "trans_dropout = 0.1\n",
    "\n",
    "model = ReportTransformer(\n",
    "    vocab_size, d_model, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward,\n",
    "    max_seq_length, pos_dropout, trans_dropout\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "    from transformer_translation.Optim import ScheduledOptim\n",
    "    import torch.nn as nn\n",
    "    from torch.optim import Adam\n",
    "    \n",
    "    for p in model.parameters():\n",
    "        if p.dim() > 1:\n",
    "            nn.init.xavier_normal_(p)\n",
    "\n",
    "    n_warmup_steps = 4000\n",
    "    optim = ScheduledOptim(\n",
    "        Adam(model.parameters(), betas=(0.9, 0.98), eps=1e-09),\n",
    "        d_model, n_warmup_steps)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsf_train_utils import prep_transf_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1 / 20] \t Step [15 / 98] \t Train Loss: 9.219210116068522\n",
      "Epoch [1 / 20] \t Step [30 / 98] \t Train Loss: 8.983137957255046\n",
      "Epoch [1 / 20] \t Step [45 / 98] \t Train Loss: 8.581922403971355\n",
      "Epoch [1 / 20] \t Step [60 / 98] \t Train Loss: 8.177903493245443\n",
      "Epoch [1 / 20] \t Step [75 / 98] \t Train Loss: 7.957618872324626\n",
      "Epoch [1 / 20] \t Step [90 / 98] \t Train Loss: 7.712112903594971\n",
      "Epoch [2 / 20] \t Step [15 / 98] \t Train Loss: 7.318874835968018\n",
      "Epoch [2 / 20] \t Step [30 / 98] \t Train Loss: 7.026069831848145\n",
      "Epoch [2 / 20] \t Step [45 / 98] \t Train Loss: 6.909017086029053\n",
      "Epoch [2 / 20] \t Step [60 / 98] \t Train Loss: 6.666585063934326\n",
      "Epoch [2 / 20] \t Step [75 / 98] \t Train Loss: 6.358024470011393\n",
      "Epoch [2 / 20] \t Step [90 / 98] \t Train Loss: 6.102291520436605\n",
      "Epoch [3 / 20] \t Step [15 / 98] \t Train Loss: 5.751453653971354\n",
      "Epoch [3 / 20] \t Step [30 / 98] \t Train Loss: 5.386170546213786\n",
      "Epoch [3 / 20] \t Step [45 / 98] \t Train Loss: 5.143763033548991\n",
      "Epoch [3 / 20] \t Step [60 / 98] \t Train Loss: 5.067904726664225\n",
      "Epoch [3 / 20] \t Step [75 / 98] \t Train Loss: 5.125506146748861\n",
      "Epoch [3 / 20] \t Step [90 / 98] \t Train Loss: 4.807605393727621\n",
      "Epoch [4 / 20] \t Step [15 / 98] \t Train Loss: 4.704819520314534\n",
      "Epoch [4 / 20] \t Step [30 / 98] \t Train Loss: 4.551481183369955\n",
      "Epoch [4 / 20] \t Step [45 / 98] \t Train Loss: 4.137640730539958\n",
      "Epoch [4 / 20] \t Step [60 / 98] \t Train Loss: 4.097169049580892\n",
      "Epoch [4 / 20] \t Step [75 / 98] \t Train Loss: 3.968618710835775\n",
      "Epoch [4 / 20] \t Step [90 / 98] \t Train Loss: 3.690752299626668\n",
      "Epoch [5 / 20] \t Step [15 / 98] \t Train Loss: 3.6435950756073\n",
      "Epoch [5 / 20] \t Step [30 / 98] \t Train Loss: 3.46779522895813\n",
      "Epoch [5 / 20] \t Step [45 / 98] \t Train Loss: 3.35092937151591\n",
      "Epoch [5 / 20] \t Step [60 / 98] \t Train Loss: 3.3154219309488933\n",
      "Epoch [5 / 20] \t Step [75 / 98] \t Train Loss: 3.4346584637959796\n",
      "Epoch [5 / 20] \t Step [90 / 98] \t Train Loss: 3.07673495610555\n",
      "Epoch [6 / 20] \t Step [15 / 98] \t Train Loss: 3.1565563360850017\n",
      "Epoch [6 / 20] \t Step [30 / 98] \t Train Loss: 2.804097827275594\n",
      "Epoch [6 / 20] \t Step [45 / 98] \t Train Loss: 3.3644787788391115\n",
      "Epoch [6 / 20] \t Step [60 / 98] \t Train Loss: 2.729116106033325\n",
      "Epoch [6 / 20] \t Step [75 / 98] \t Train Loss: 2.928639562924703\n",
      "Epoch [6 / 20] \t Step [90 / 98] \t Train Loss: 2.8872475624084473\n",
      "Epoch [7 / 20] \t Step [15 / 98] \t Train Loss: 2.8571531454722088\n",
      "Epoch [7 / 20] \t Step [30 / 98] \t Train Loss: 2.7125316222508746\n",
      "Epoch [7 / 20] \t Step [45 / 98] \t Train Loss: 2.667478362719218\n",
      "Epoch [7 / 20] \t Step [60 / 98] \t Train Loss: 2.3361676772435507\n",
      "Epoch [7 / 20] \t Step [75 / 98] \t Train Loss: 2.637659486134847\n",
      "Epoch [7 / 20] \t Step [90 / 98] \t Train Loss: 2.7942076365152997\n",
      "Epoch [8 / 20] \t Step [15 / 98] \t Train Loss: 2.32271089553833\n",
      "Epoch [8 / 20] \t Step [30 / 98] \t Train Loss: 2.734414744377136\n",
      "Epoch [8 / 20] \t Step [45 / 98] \t Train Loss: 2.236454892158508\n",
      "Epoch [8 / 20] \t Step [60 / 98] \t Train Loss: 2.6008010387420653\n",
      "Epoch [8 / 20] \t Step [75 / 98] \t Train Loss: 2.4344470739364623\n",
      "Epoch [8 / 20] \t Step [90 / 98] \t Train Loss: 2.3085601727167764\n",
      "Epoch [9 / 20] \t Step [15 / 98] \t Train Loss: 2.1272663354873655\n",
      "Epoch [9 / 20] \t Step [30 / 98] \t Train Loss: 2.394089659055074\n",
      "Epoch [9 / 20] \t Step [45 / 98] \t Train Loss: 2.096013832092285\n",
      "Epoch [9 / 20] \t Step [60 / 98] \t Train Loss: 2.2723789771397906\n",
      "Epoch [9 / 20] \t Step [75 / 98] \t Train Loss: 2.411325224240621\n",
      "Epoch [9 / 20] \t Step [90 / 98] \t Train Loss: 2.274303674697876\n",
      "Epoch [10 / 20] \t Step [15 / 98] \t Train Loss: 2.174493098258972\n",
      "Epoch [10 / 20] \t Step [30 / 98] \t Train Loss: 1.9401630798975626\n",
      "Epoch [10 / 20] \t Step [45 / 98] \t Train Loss: 2.014808503786723\n",
      "Epoch [10 / 20] \t Step [60 / 98] \t Train Loss: 2.3935121138890585\n",
      "Epoch [10 / 20] \t Step [75 / 98] \t Train Loss: 1.9191593885421754\n",
      "Epoch [10 / 20] \t Step [90 / 98] \t Train Loss: 2.086322546005249\n",
      "Epoch [11 / 20] \t Step [15 / 98] \t Train Loss: 2.240743104616801\n",
      "Epoch [11 / 20] \t Step [30 / 98] \t Train Loss: 1.8096510489781699\n",
      "Epoch [11 / 20] \t Step [45 / 98] \t Train Loss: 1.8952112754185995\n",
      "Epoch [11 / 20] \t Step [60 / 98] \t Train Loss: 1.9882790962855021\n",
      "Epoch [11 / 20] \t Step [75 / 98] \t Train Loss: 1.9383304516474407\n",
      "Epoch [11 / 20] \t Step [90 / 98] \t Train Loss: 1.8262770573298137\n",
      "Epoch [12 / 20] \t Step [15 / 98] \t Train Loss: 1.4684408823649089\n",
      "Epoch [12 / 20] \t Step [30 / 98] \t Train Loss: 1.9618361632029215\n",
      "Epoch [12 / 20] \t Step [45 / 98] \t Train Loss: 1.9076358397801718\n",
      "Epoch [12 / 20] \t Step [60 / 98] \t Train Loss: 2.0027282158533732\n",
      "Epoch [12 / 20] \t Step [75 / 98] \t Train Loss: 1.7599810242652894\n",
      "Epoch [12 / 20] \t Step [90 / 98] \t Train Loss: 1.9116981585820516\n",
      "Epoch [13 / 20] \t Step [15 / 98] \t Train Loss: 1.902226495742798\n",
      "Epoch [13 / 20] \t Step [30 / 98] \t Train Loss: 1.6964193344116212\n",
      "Epoch [13 / 20] \t Step [45 / 98] \t Train Loss: 1.7847453832626343\n",
      "Epoch [13 / 20] \t Step [60 / 98] \t Train Loss: 1.7197154919306437\n",
      "Epoch [13 / 20] \t Step [75 / 98] \t Train Loss: 1.911759869257609\n",
      "Epoch [13 / 20] \t Step [90 / 98] \t Train Loss: 1.5787799914677938\n",
      "Epoch [14 / 20] \t Step [15 / 98] \t Train Loss: 1.6614086508750916\n",
      "Epoch [14 / 20] \t Step [30 / 98] \t Train Loss: 1.4277920762697855\n",
      "Epoch [14 / 20] \t Step [45 / 98] \t Train Loss: 1.6580149809519449\n",
      "Epoch [14 / 20] \t Step [60 / 98] \t Train Loss: 1.9670834143956502\n",
      "Epoch [14 / 20] \t Step [75 / 98] \t Train Loss: 1.650149130821228\n",
      "Epoch [14 / 20] \t Step [90 / 98] \t Train Loss: 1.7490259170532227\n",
      "Epoch [15 / 20] \t Step [15 / 98] \t Train Loss: 1.6104546268781026\n",
      "Epoch [15 / 20] \t Step [30 / 98] \t Train Loss: 1.786435846487681\n",
      "Epoch [15 / 20] \t Step [45 / 98] \t Train Loss: 1.6266278386116029\n",
      "Epoch [15 / 20] \t Step [60 / 98] \t Train Loss: 1.6893919070561727\n",
      "Epoch [15 / 20] \t Step [75 / 98] \t Train Loss: 1.5076137860616048\n",
      "Epoch [15 / 20] \t Step [90 / 98] \t Train Loss: 1.4496137142181396\n",
      "Epoch [16 / 20] \t Step [15 / 98] \t Train Loss: 1.4564459244410197\n",
      "Epoch [16 / 20] \t Step [30 / 98] \t Train Loss: 1.6688586076100667\n",
      "Epoch [16 / 20] \t Step [45 / 98] \t Train Loss: 1.514677107334137\n",
      "Epoch [16 / 20] \t Step [60 / 98] \t Train Loss: 1.6312963048617044\n",
      "Epoch [16 / 20] \t Step [75 / 98] \t Train Loss: 1.550148336092631\n",
      "Epoch [16 / 20] \t Step [90 / 98] \t Train Loss: 1.506196141242981\n",
      "Epoch [17 / 20] \t Step [15 / 98] \t Train Loss: 1.2243689020474753\n",
      "Epoch [17 / 20] \t Step [30 / 98] \t Train Loss: 1.3997031529744466\n",
      "Epoch [17 / 20] \t Step [45 / 98] \t Train Loss: 1.4216000398000082\n",
      "Epoch [17 / 20] \t Step [60 / 98] \t Train Loss: 1.554189630349477\n",
      "Epoch [17 / 20] \t Step [75 / 98] \t Train Loss: 1.7414953708648682\n",
      "Epoch [17 / 20] \t Step [90 / 98] \t Train Loss: 1.4501397172609964\n",
      "Epoch [18 / 20] \t Step [15 / 98] \t Train Loss: 1.383399816354116\n",
      "Epoch [18 / 20] \t Step [30 / 98] \t Train Loss: 1.3405598878860474\n",
      "Epoch [18 / 20] \t Step [45 / 98] \t Train Loss: 1.559139875570933\n",
      "Epoch [18 / 20] \t Step [60 / 98] \t Train Loss: 1.2344476679960887\n",
      "Epoch [18 / 20] \t Step [75 / 98] \t Train Loss: 1.449225413799286\n",
      "Epoch [18 / 20] \t Step [90 / 98] \t Train Loss: 1.4028814017772675\n",
      "Epoch [19 / 20] \t Step [15 / 98] \t Train Loss: 1.2340355555216471\n",
      "Epoch [19 / 20] \t Step [30 / 98] \t Train Loss: 1.191843279202779\n",
      "Epoch [19 / 20] \t Step [45 / 98] \t Train Loss: 1.3936473965644836\n",
      "Epoch [19 / 20] \t Step [60 / 98] \t Train Loss: 1.4212918877601624\n",
      "Epoch [19 / 20] \t Step [75 / 98] \t Train Loss: 1.2672335048516592\n",
      "Epoch [19 / 20] \t Step [90 / 98] \t Train Loss: 1.5056459546089171\n",
      "Epoch [20 / 20] \t Step [15 / 98] \t Train Loss: 1.1897446433703105\n",
      "Epoch [20 / 20] \t Step [30 / 98] \t Train Loss: 1.2115268766880036\n",
      "Epoch [20 / 20] \t Step [45 / 98] \t Train Loss: 1.2839049220085144\n",
      "Epoch [20 / 20] \t Step [60 / 98] \t Train Loss: 1.3267580986022949\n",
      "Epoch [20 / 20] \t Step [75 / 98] \t Train Loss: 1.5687268694241843\n",
      "Epoch [20 / 20] \t Step [90 / 98] \t Train Loss: 1.032408994436264\n",
      "CPU times: user 3h 39min 8s, sys: 7min 52s, total: 3h 47min 1s\n",
      "Wall time: 5min 17s\n"
     ]
    }
   ],
   "source": [
    "    %%time\n",
    "    print_every = 15\n",
    "    num_epochs = 20\n",
    "    model.train()\n",
    "\n",
    "    lowest_val = 1e9\n",
    "    val_losses = []\n",
    "    total_step = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        total_loss = 0\n",
    "\n",
    "        for step, (src, src_key_padding_mask, tgt, tgt_key_padding_mask) in enumerate(iter(loader)):\n",
    "            total_step += 1\n",
    "\n",
    "            src, src_key_padding_mask, tgt, tgt_key_padding_mask, memory_key_padding_mask, tgt_inp, tgt_out, tgt_mask = prep_transf_inputs(\n",
    "                src, src_key_padding_mask, tgt, tgt_key_padding_mask, device)\n",
    "            \n",
    "            optim.zero_grad()\n",
    "            outputs = model(src, tgt_inp, src_key_padding_mask, tgt_key_padding_mask[:, :-1], memory_key_padding_mask, tgt_mask)\n",
    "            loss = criterion(rearrange(outputs, 'b t v -> (b t) v'), rearrange(tgt_out, 'b o -> (b o)'))\n",
    "\n",
    "            loss.backward()\n",
    "            optim.step_and_update_lr()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            if step % print_every == print_every - 1:\n",
    "                print(f'Epoch [{epoch + 1} / {num_epochs}] \\t Step [{step + 1} / {len(loader)}] \\t '\n",
    "                      f'Train Loss: {total_loss / print_every}')\n",
    "                total_loss = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# assess perf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsf_infer_utils import infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 25s, sys: 7.52 s, total: 3min 32s\n",
      "Wall time: 5.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pred_list, tgt_list = infer(model, loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.metrics import bleu_score\n",
    "from tsf_utils import format_list_for_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.7 s, sys: 32 ms, total: 11.7 s\n",
      "Wall time: 11.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4271217530833602"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "pred_list_bleu, tgt_list_bleu = format_list_for_bleu(pred_list, tgt_list)\n",
    "bleu_score(pred_list_bleu, tgt_list_bleu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create vocab dicts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_index2word = dict(zip(range(len(dataset.countvec.vocabulary)), dataset.countvec.vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_translation.dataset import load_report_voc\n",
    "reports_index2word = load_report_voc(\n",
    "    os.path.join(data_path, 'reports', 'voc.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### assess nat lg perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsf_utils import print_nl_pred_vs_tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "k = 10\n",
    "sel_idx = random.choices(range(len(pred_list)), k=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET:    . cm nodular density in the anterior costophrenic xxxx on the lateral view which could represent overlapping shadows or actual pulmonary nodule . recommend followup with chest ct . heart size is normal . prior calcified granulomatous disease . on the lateral view in the anterior costophrenic xxxx there is a . x cm nodular density which seems to be present previously but is more nodular in appearance on this examination . no pleural effusion or pneumothorax . endplate degenerative changes of the thoracolumbar spine and mild scoliosis are unchanged . . SOS\n",
      "PREDICTION:   . no interstitial opacities in the lung segment xxxx . the lateral view . may be chronic hypertension or infection pulmonary nodule . no xxxx chest xxxx for . recommend size within within . no granulomatous hilar disease . no the central view and appearance right chest xxxx . are a cm no xxxx nodular opacities in may to be related on seen not not nodular in appearance . the exam . no definite effusion or pneumothoraces . degenerative changes changes of the thoracic spine . chronic degenerative are present . . .\n",
      "\n",
      "\n",
      "TARGET:    . no acute cardiopulmonary abnormalities . normal and stable cardiomediastinal contours . no pneumothorax pleural effusions or significant pulmonary edema . no focal lung consolidation . .\n",
      "PREDICTION:  no . no acute pulmonary abnormality . . cardiomediastinal mediastinal cardiomediastinal contours . no focal or effusions or focal change edema . . focal lung consolidation . .\n",
      "\n",
      "\n",
      "TARGET:   negative chest . the lungs are clear . the cardiomediastinal silhouette is within normal limits . no pneumothorax or pleural effusion . .\n",
      "PREDICTION:  no chest . the lungs are clear . the cardiomediastinal silhouette is within normal limits . no pneumothorax or pleural effusion . .\n",
      "\n",
      "\n",
      "TARGET:    . no acute cardiopulmonary disease . . xxxx scarring or atelectasis right midlung . . mild cardiomegaly . . mild cardiomegaly . mediastinal normal width . pulmonary vasculature within normal limits . the lungs are well aerated . there is no pneumothorax pleural effusion or focal consolidation . xxxx scarring or atelectasis right midlung . .\n",
      "PREDICTION:   . no acute cardiopulmonary abnormality . . stable opacities . scarring . lung . the no cardiomegaly . no no elevation . normal contours pulmonary and no vascularity within normal limits . no lungs are clear aerated . no is minimal focal pleural effusion or focal airspace . mild opacities or atelectasis . lung . mild\n",
      "\n",
      "\n",
      "TARGET:   heart size is normal . calcified right paratracheal lymph xxxx calcified granuloma in the peripheral portion right upper lobe . no arteriographic evidence of tuberculosis . .\n",
      "PREDICTION:  no size is normal and lungs mediastinal hilar lymph granuloma granuloma granuloma . the right lung of lung lobe . no focal evidence of tuberculosis . no\n",
      "\n",
      "\n",
      "TARGET:   no acute findings . cardiac and mediastinal contours are within normal limits . the lungs are clear . bony structures are intact . .\n",
      "PREDICTION:  no acute cardiopulmonary . the and mediastinal contours are within normal limits . the lungs are clear . bony structures are intact . .\n",
      "\n",
      "\n",
      "TARGET:    . no acute cardiopulmonary abnormalities clear lungs bilaterally . no pneumothorax or pleural effusion . normal cardiac contours . SOS\n",
      "PREDICTION:  no . no acute pulmonary abnormality . . . . no focal . large effusion . normal heart contour . clear\n",
      "\n",
      "\n",
      "TARGET:    . moderate thoracic spondylosis . . no acute cardiopulmonary abnormality . heart size is upper limits of normal for ap projection . mediastinal contours and pulmonary vasculature are unremarkable . the patient s chin obscures the bilateral lung apices . there is no focal airspace consolidation . no visible pleural effusion or pneumothorax . no displaced rib fractures are seen . there are moderate degenerative changes along the thoracic spine . .\n",
      "PREDICTION:  no . no to aorta . . . acute pulmonary abnormality . . size and upper limits of normal . appearance projection . lungs contour and pulmonary vascularity are within . no lungs is markings obscures appearance bilateral interstitial bases . no are no focal airspace consolidation pleural no pleural pleural effusion or pneumothorax . . acute rib fractures identified identified . . are degenerative degenerative changes of the spine spine . .\n",
      "\n",
      "\n",
      "TARGET:    . no acute cardiopulmonary findings . no focal consolidation . no visualized pneumothorax . the heart size is normal . no large pleural effusions . the cardiomediastinal silhouette is grossly unremarkable . .\n",
      "PREDICTION:  no . no acute cardiopulmonary abnormality . no focal alveolar . no visualized pneumothorax . no heart size is normal . the large pleural effusions . the xxxx silhouette is grossly unremarkable . .\n",
      "\n",
      "\n",
      "TARGET:   no radiographic evidence of acute cardiopulmonary abnormality . the heart size is normal . the mediastinal contour is within normal limits . there are no focal infiltrates . there is prominent epipericardial fat . there are no nodules or masses . no visible pneumothorax . no visible pleural fluid . right th and th rib deformities are noted . there is no visible free intraperitoneal air under the diaphragm . .\n",
      "PREDICTION:  no acute evidence of active cardiopulmonary process . stable lungs size and normal . the pulmonary contour and within normal limits . the is no focal air . no is no interstitial fat . there are no nodules or masses . no visible pneumothorax . no visible pleural fluid . the hilar and right rib fractures are noted . no are no acute free intraperitoneal air under the diaphragm . .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_nl_pred_vs_tgt(\n",
    "                [pred_list[i] for i in sel_idx]\n",
    "                ,[tgt_list[i] for i in sel_idx]\n",
    "                ,reports_index2word\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
