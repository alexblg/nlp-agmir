{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_translation.dataset import ParallelLanguageDataset, load_pickle\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r\"/home/alex/data/nlp/agmir/transf_processed_data\"\n",
    "#data_path = 'transformer_translation/data/processed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = load_pickle('20200525_splits.pkl')\n",
    "countvec = load_pickle('20200525_countvec.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n"
     ]
    }
   ],
   "source": [
    "num_tokens = 2000\n",
    "max_seq_length = 96\n",
    "dataset = ParallelLanguageDataset(\n",
    "    os.path.join(data_path, 'tags/set.pkl')\n",
    "    ,os.path.join(data_path, 'reports/set.pkl')\n",
    "    ,num_tokens\n",
    "    ,max_seq_length\n",
    "    ,idxs=splits['train']\n",
    ")\n",
    "loader = DataLoader(dataset, batch_size=1, shuffle=True, num_workers=4, pin_memory=True)\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "val_dataset = ParallelLanguageDataset(\n",
    "    os.path.join(data_path, 'tags/set.pkl')\n",
    "    ,os.path.join(data_path, 'reports/set.pkl')\n",
    "    ,num_tokens\n",
    "    ,max_seq_length\n",
    "    ,idxs=splits['val']\n",
    ")\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=True, num_workers=4, pin_memory=True)\n",
    "print(len(val_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_translation.model import LanguageTransformer, ReportTransformer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000 + 4#1952#\n",
    "nhead = 8\n",
    "d_model = 512\n",
    "num_encoder_layers = 6\n",
    "num_decoder_layers = 6\n",
    "dim_feedforward = 2048\n",
    "pos_dropout = 0.1\n",
    "trans_dropout = 0.1\n",
    "\n",
    "model = ReportTransformer2(\n",
    "    vocab_size, d_model, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward,\n",
    "    max_seq_length, pos_dropout, trans_dropout\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "    from transformer_translation.Optim import ScheduledOptim\n",
    "    import torch.nn as nn\n",
    "    from torch.optim import Adam\n",
    "    \n",
    "    for p in model.parameters():\n",
    "        if p.dim() > 1:\n",
    "            nn.init.xavier_normal_(p)\n",
    "\n",
    "    n_warmup_steps = 4000\n",
    "    optim = ScheduledOptim(\n",
    "        Adam(model.parameters(), betas=(0.9, 0.98), eps=1e-09),\n",
    "        d_model, n_warmup_steps)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsf_infer_utils import prep_transf_inputs2, infer2\n",
    "from torchtext.data.metrics import bleu_score\n",
    "from tsf_utils import format_list_for_bleu, get_bleu_from_loader2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1 / 30] \t Step [15 / 79] \t Train Loss: 9.206\n",
      "Epoch [1 / 30] \t Step [30 / 79] \t Train Loss: 8.944\n",
      "Epoch [1 / 30] \t Step [45 / 79] \t Train Loss: 8.571\n",
      "Epoch [1 / 30] \t Step [60 / 79] \t Train Loss: 8.167\n",
      "Epoch [1 / 30] \t Step [75 / 79] \t Train Loss: 8.003\n",
      "Epoch [1 / 30]:\n",
      "\ttrain BLEU: 0.00%\n",
      "\tval BLEU: 0.00%\n",
      "\n",
      "\n",
      "Epoch [2 / 30] \t Step [15 / 79] \t Train Loss: 7.683\n",
      "Epoch [2 / 30] \t Step [30 / 79] \t Train Loss: 7.501\n",
      "Epoch [2 / 30] \t Step [45 / 79] \t Train Loss: 7.336\n",
      "Epoch [2 / 30] \t Step [60 / 79] \t Train Loss: 7.100\n",
      "Epoch [2 / 30] \t Step [75 / 79] \t Train Loss: 6.787\n",
      "Epoch [2 / 30]:\n",
      "\ttrain BLEU: 0.00%\n",
      "\tval BLEU: 0.00%\n",
      "\n",
      "\n",
      "Epoch [3 / 30] \t Step [15 / 79] \t Train Loss: 6.496\n",
      "Epoch [3 / 30] \t Step [30 / 79] \t Train Loss: 6.167\n",
      "Epoch [3 / 30] \t Step [45 / 79] \t Train Loss: 5.968\n",
      "Epoch [3 / 30] \t Step [60 / 79] \t Train Loss: 5.624\n",
      "Epoch [3 / 30] \t Step [75 / 79] \t Train Loss: 5.437\n",
      "Epoch [3 / 30]:\n",
      "\ttrain BLEU: 0.00%\n",
      "\tval BLEU: 0.00%\n",
      "\n",
      "\n",
      "Epoch [4 / 30] \t Step [15 / 79] \t Train Loss: 5.168\n",
      "Epoch [4 / 30] \t Step [30 / 79] \t Train Loss: 4.983\n",
      "Epoch [4 / 30] \t Step [45 / 79] \t Train Loss: 4.745\n",
      "Epoch [4 / 30] \t Step [60 / 79] \t Train Loss: 4.475\n",
      "Epoch [4 / 30] \t Step [75 / 79] \t Train Loss: 4.254\n",
      "Epoch [4 / 30]:\n",
      "\ttrain BLEU: 3.36%\n",
      "\tval BLEU: 2.42%\n",
      "\n",
      "\n",
      "Epoch [5 / 30] \t Step [15 / 79] \t Train Loss: 4.067\n",
      "Epoch [5 / 30] \t Step [30 / 79] \t Train Loss: 3.919\n",
      "Epoch [5 / 30] \t Step [45 / 79] \t Train Loss: 4.028\n",
      "Epoch [5 / 30] \t Step [60 / 79] \t Train Loss: 3.791\n",
      "Epoch [5 / 30] \t Step [75 / 79] \t Train Loss: 3.382\n",
      "Epoch [5 / 30]:\n",
      "\ttrain BLEU: 10.66%\n",
      "\tval BLEU: 7.50%\n",
      "\n",
      "\n",
      "Epoch [6 / 30] \t Step [15 / 79] \t Train Loss: 3.557\n",
      "Epoch [6 / 30] \t Step [30 / 79] \t Train Loss: 3.130\n",
      "Epoch [6 / 30] \t Step [45 / 79] \t Train Loss: 3.360\n",
      "Epoch [6 / 30] \t Step [60 / 79] \t Train Loss: 3.355\n",
      "Epoch [6 / 30] \t Step [75 / 79] \t Train Loss: 3.088\n",
      "Epoch [6 / 30]:\n",
      "\ttrain BLEU: 12.56%\n",
      "\tval BLEU: 8.88%\n",
      "\n",
      "\n",
      "Epoch [7 / 30] \t Step [15 / 79] \t Train Loss: 2.802\n",
      "Epoch [7 / 30] \t Step [30 / 79] \t Train Loss: 3.138\n",
      "Epoch [7 / 30] \t Step [45 / 79] \t Train Loss: 3.026\n",
      "Epoch [7 / 30] \t Step [60 / 79] \t Train Loss: 2.914\n",
      "Epoch [7 / 30] \t Step [75 / 79] \t Train Loss: 2.667\n",
      "Epoch [7 / 30]:\n",
      "\ttrain BLEU: 15.47%\n",
      "\tval BLEU: 11.01%\n",
      "\n",
      "\n",
      "Epoch [8 / 30] \t Step [15 / 79] \t Train Loss: 2.674\n",
      "Epoch [8 / 30] \t Step [30 / 79] \t Train Loss: 2.519\n",
      "Epoch [8 / 30] \t Step [45 / 79] \t Train Loss: 2.609\n",
      "Epoch [8 / 30] \t Step [60 / 79] \t Train Loss: 2.689\n",
      "Epoch [8 / 30] \t Step [75 / 79] \t Train Loss: 2.727\n",
      "Epoch [8 / 30]:\n",
      "\ttrain BLEU: 18.43%\n",
      "\tval BLEU: 12.79%\n",
      "\n",
      "\n",
      "Epoch [9 / 30] \t Step [15 / 79] \t Train Loss: 2.269\n",
      "Epoch [9 / 30] \t Step [30 / 79] \t Train Loss: 2.614\n",
      "Epoch [9 / 30] \t Step [45 / 79] \t Train Loss: 2.409\n",
      "Epoch [9 / 30] \t Step [60 / 79] \t Train Loss: 2.588\n",
      "Epoch [9 / 30] \t Step [75 / 79] \t Train Loss: 2.225\n",
      "Epoch [9 / 30]:\n",
      "\ttrain BLEU: 21.68%\n",
      "\tval BLEU: 14.84%\n",
      "\n",
      "\n",
      "Epoch [10 / 30] \t Step [15 / 79] \t Train Loss: 1.887\n",
      "Epoch [10 / 30] \t Step [30 / 79] \t Train Loss: 2.041\n",
      "Epoch [10 / 30] \t Step [45 / 79] \t Train Loss: 2.407\n",
      "Epoch [10 / 30] \t Step [60 / 79] \t Train Loss: 2.249\n",
      "Epoch [10 / 30] \t Step [75 / 79] \t Train Loss: 2.568\n",
      "Epoch [10 / 30]:\n",
      "\ttrain BLEU: 24.50%\n",
      "\tval BLEU: 16.68%\n",
      "\n",
      "\n",
      "Epoch [11 / 30] \t Step [15 / 79] \t Train Loss: 2.207\n",
      "Epoch [11 / 30] \t Step [30 / 79] \t Train Loss: 1.797\n",
      "Epoch [11 / 30] \t Step [45 / 79] \t Train Loss: 2.349\n",
      "Epoch [11 / 30] \t Step [60 / 79] \t Train Loss: 2.175\n",
      "Epoch [11 / 30] \t Step [75 / 79] \t Train Loss: 2.192\n",
      "Epoch [11 / 30]:\n",
      "\ttrain BLEU: 26.00%\n",
      "\tval BLEU: 18.26%\n",
      "\n",
      "\n",
      "Epoch [12 / 30] \t Step [15 / 79] \t Train Loss: 2.239\n",
      "Epoch [12 / 30] \t Step [30 / 79] \t Train Loss: 1.753\n",
      "Epoch [12 / 30] \t Step [45 / 79] \t Train Loss: 1.954\n",
      "Epoch [12 / 30] \t Step [60 / 79] \t Train Loss: 2.034\n",
      "Epoch [12 / 30] \t Step [75 / 79] \t Train Loss: 1.740\n",
      "Epoch [12 / 30]:\n",
      "\ttrain BLEU: 29.76%\n",
      "\tval BLEU: 20.09%\n",
      "\n",
      "\n",
      "Epoch [13 / 30] \t Step [15 / 79] \t Train Loss: 2.191\n",
      "Epoch [13 / 30] \t Step [30 / 79] \t Train Loss: 1.880\n",
      "Epoch [13 / 30] \t Step [45 / 79] \t Train Loss: 1.717\n",
      "Epoch [13 / 30] \t Step [60 / 79] \t Train Loss: 1.879\n",
      "Epoch [13 / 30] \t Step [75 / 79] \t Train Loss: 1.744\n",
      "Epoch [13 / 30]:\n",
      "\ttrain BLEU: 29.69%\n",
      "\tval BLEU: 20.49%\n",
      "\n",
      "\n",
      "Epoch [14 / 30] \t Step [15 / 79] \t Train Loss: 1.738\n",
      "Epoch [14 / 30] \t Step [30 / 79] \t Train Loss: 1.722\n",
      "Epoch [14 / 30] \t Step [45 / 79] \t Train Loss: 1.947\n",
      "Epoch [14 / 30] \t Step [60 / 79] \t Train Loss: 1.555\n",
      "Epoch [14 / 30] \t Step [75 / 79] \t Train Loss: 1.942\n",
      "Epoch [14 / 30]:\n",
      "\ttrain BLEU: 31.68%\n",
      "\tval BLEU: 21.72%\n",
      "\n",
      "\n",
      "Epoch [15 / 30] \t Step [15 / 79] \t Train Loss: 1.869\n",
      "Epoch [15 / 30] \t Step [30 / 79] \t Train Loss: 1.649\n",
      "Epoch [15 / 30] \t Step [45 / 79] \t Train Loss: 1.809\n",
      "Epoch [15 / 30] \t Step [60 / 79] \t Train Loss: 1.640\n",
      "Epoch [15 / 30] \t Step [75 / 79] \t Train Loss: 1.585\n",
      "Epoch [15 / 30]:\n",
      "\ttrain BLEU: 32.31%\n",
      "\tval BLEU: 21.80%\n",
      "\n",
      "\n",
      "Epoch [16 / 30] \t Step [15 / 79] \t Train Loss: 1.723\n",
      "Epoch [16 / 30] \t Step [30 / 79] \t Train Loss: 1.572\n",
      "Epoch [16 / 30] \t Step [45 / 79] \t Train Loss: 1.785\n",
      "Epoch [16 / 30] \t Step [60 / 79] \t Train Loss: 1.613\n",
      "Epoch [16 / 30] \t Step [75 / 79] \t Train Loss: 1.446\n",
      "Epoch [16 / 30]:\n",
      "\ttrain BLEU: 36.64%\n",
      "\tval BLEU: 24.62%\n",
      "\n",
      "\n",
      "Epoch [17 / 30] \t Step [15 / 79] \t Train Loss: 1.483\n",
      "Epoch [17 / 30] \t Step [30 / 79] \t Train Loss: 1.473\n",
      "Epoch [17 / 30] \t Step [45 / 79] \t Train Loss: 1.515\n",
      "Epoch [17 / 30] \t Step [60 / 79] \t Train Loss: 1.397\n",
      "Epoch [17 / 30] \t Step [75 / 79] \t Train Loss: 1.839\n",
      "Epoch [17 / 30]:\n",
      "\ttrain BLEU: 38.42%\n",
      "\tval BLEU: 25.93%\n",
      "\n",
      "\n",
      "Epoch [18 / 30] \t Step [15 / 79] \t Train Loss: 1.420\n",
      "Epoch [18 / 30] \t Step [30 / 79] \t Train Loss: 1.613\n",
      "Epoch [18 / 30] \t Step [45 / 79] \t Train Loss: 1.525\n",
      "Epoch [18 / 30] \t Step [60 / 79] \t Train Loss: 1.383\n",
      "Epoch [18 / 30] \t Step [75 / 79] \t Train Loss: 1.435\n",
      "Epoch [18 / 30]:\n",
      "\ttrain BLEU: 38.54%\n",
      "\tval BLEU: 25.49%\n",
      "\n",
      "\n",
      "Epoch [19 / 30] \t Step [15 / 79] \t Train Loss: 1.117\n",
      "Epoch [19 / 30] \t Step [30 / 79] \t Train Loss: 1.473\n",
      "Epoch [19 / 30] \t Step [45 / 79] \t Train Loss: 1.380\n",
      "Epoch [19 / 30] \t Step [60 / 79] \t Train Loss: 1.607\n",
      "Epoch [19 / 30] \t Step [75 / 79] \t Train Loss: 1.365\n",
      "Epoch [19 / 30]:\n",
      "\ttrain BLEU: 39.72%\n",
      "\tval BLEU: 26.28%\n",
      "\n",
      "\n",
      "Epoch [20 / 30] \t Step [15 / 79] \t Train Loss: 1.468\n",
      "Epoch [20 / 30] \t Step [30 / 79] \t Train Loss: 1.195\n",
      "Epoch [20 / 30] \t Step [45 / 79] \t Train Loss: 1.214\n",
      "Epoch [20 / 30] \t Step [60 / 79] \t Train Loss: 1.435\n",
      "Epoch [20 / 30] \t Step [75 / 79] \t Train Loss: 1.392\n",
      "Epoch [20 / 30]:\n",
      "\ttrain BLEU: 41.47%\n",
      "\tval BLEU: 26.63%\n",
      "\n",
      "\n",
      "Epoch [21 / 30] \t Step [15 / 79] \t Train Loss: 1.250\n",
      "Epoch [21 / 30] \t Step [30 / 79] \t Train Loss: 1.396\n",
      "Epoch [21 / 30] \t Step [45 / 79] \t Train Loss: 1.297\n",
      "Epoch [21 / 30] \t Step [60 / 79] \t Train Loss: 1.372\n",
      "Epoch [21 / 30] \t Step [75 / 79] \t Train Loss: 1.182\n",
      "Epoch [21 / 30]:\n",
      "\ttrain BLEU: 42.53%\n",
      "\tval BLEU: 27.13%\n",
      "\n",
      "\n",
      "Epoch [22 / 30] \t Step [15 / 79] \t Train Loss: 1.231\n",
      "Epoch [22 / 30] \t Step [30 / 79] \t Train Loss: 1.359\n",
      "Epoch [22 / 30] \t Step [45 / 79] \t Train Loss: 1.227\n",
      "Epoch [22 / 30] \t Step [60 / 79] \t Train Loss: 1.083\n",
      "Epoch [22 / 30] \t Step [75 / 79] \t Train Loss: 1.465\n",
      "Epoch [22 / 30]:\n",
      "\ttrain BLEU: 42.73%\n",
      "\tval BLEU: 27.49%\n",
      "\n",
      "\n",
      "Epoch [23 / 30] \t Step [15 / 79] \t Train Loss: 1.087\n",
      "Epoch [23 / 30] \t Step [30 / 79] \t Train Loss: 1.260\n",
      "Epoch [23 / 30] \t Step [45 / 79] \t Train Loss: 1.138\n",
      "Epoch [23 / 30] \t Step [60 / 79] \t Train Loss: 1.171\n",
      "Epoch [23 / 30] \t Step [75 / 79] \t Train Loss: 1.368\n",
      "Epoch [23 / 30]:\n",
      "\ttrain BLEU: 45.89%\n",
      "\tval BLEU: 28.80%\n",
      "\n",
      "\n",
      "Epoch [24 / 30] \t Step [15 / 79] \t Train Loss: 1.177\n",
      "Epoch [24 / 30] \t Step [30 / 79] \t Train Loss: 1.198\n",
      "Epoch [24 / 30] \t Step [45 / 79] \t Train Loss: 1.050\n",
      "Epoch [24 / 30] \t Step [60 / 79] \t Train Loss: 1.114\n",
      "Epoch [24 / 30] \t Step [75 / 79] \t Train Loss: 1.215\n",
      "Epoch [24 / 30]:\n",
      "\ttrain BLEU: 47.27%\n",
      "\tval BLEU: 28.61%\n",
      "\n",
      "\n",
      "Epoch [25 / 30] \t Step [15 / 79] \t Train Loss: 1.023\n",
      "Epoch [25 / 30] \t Step [30 / 79] \t Train Loss: 0.987\n",
      "Epoch [25 / 30] \t Step [45 / 79] \t Train Loss: 1.031\n",
      "Epoch [25 / 30] \t Step [60 / 79] \t Train Loss: 1.389\n",
      "Epoch [25 / 30] \t Step [75 / 79] \t Train Loss: 0.997\n",
      "Epoch [25 / 30]:\n",
      "\ttrain BLEU: 47.66%\n",
      "\tval BLEU: 28.97%\n",
      "\n",
      "\n",
      "Epoch [26 / 30] \t Step [15 / 79] \t Train Loss: 0.993\n",
      "Epoch [26 / 30] \t Step [30 / 79] \t Train Loss: 1.104\n",
      "Epoch [26 / 30] \t Step [45 / 79] \t Train Loss: 0.890\n",
      "Epoch [26 / 30] \t Step [60 / 79] \t Train Loss: 1.109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26 / 30] \t Step [75 / 79] \t Train Loss: 1.139\n",
      "Epoch [26 / 30]:\n",
      "\ttrain BLEU: 49.64%\n",
      "\tval BLEU: 29.25%\n",
      "\n",
      "\n",
      "Epoch [27 / 30] \t Step [15 / 79] \t Train Loss: 1.094\n",
      "Epoch [27 / 30] \t Step [30 / 79] \t Train Loss: 0.911\n",
      "Epoch [27 / 30] \t Step [45 / 79] \t Train Loss: 0.750\n",
      "Epoch [27 / 30] \t Step [60 / 79] \t Train Loss: 1.172\n",
      "Epoch [27 / 30] \t Step [75 / 79] \t Train Loss: 1.083\n",
      "Epoch [27 / 30]:\n",
      "\ttrain BLEU: 49.71%\n",
      "\tval BLEU: 29.15%\n",
      "\n",
      "\n",
      "Epoch [28 / 30] \t Step [15 / 79] \t Train Loss: 0.836\n",
      "Epoch [28 / 30] \t Step [30 / 79] \t Train Loss: 0.991\n",
      "Epoch [28 / 30] \t Step [45 / 79] \t Train Loss: 0.991\n",
      "Epoch [28 / 30] \t Step [60 / 79] \t Train Loss: 1.013\n",
      "Epoch [28 / 30] \t Step [75 / 79] \t Train Loss: 0.977\n",
      "Epoch [28 / 30]:\n",
      "\ttrain BLEU: 51.90%\n",
      "\tval BLEU: 29.21%\n",
      "\n",
      "\n",
      "Epoch [29 / 30] \t Step [15 / 79] \t Train Loss: 1.018\n",
      "Epoch [29 / 30] \t Step [30 / 79] \t Train Loss: 0.883\n",
      "Epoch [29 / 30] \t Step [45 / 79] \t Train Loss: 0.910\n",
      "Epoch [29 / 30] \t Step [60 / 79] \t Train Loss: 0.799\n",
      "Epoch [29 / 30] \t Step [75 / 79] \t Train Loss: 1.016\n",
      "Epoch [29 / 30]:\n",
      "\ttrain BLEU: 53.75%\n",
      "\tval BLEU: 29.24%\n",
      "\n",
      "\n",
      "Epoch [30 / 30] \t Step [15 / 79] \t Train Loss: 0.789\n",
      "Epoch [30 / 30] \t Step [30 / 79] \t Train Loss: 0.797\n",
      "Epoch [30 / 30] \t Step [45 / 79] \t Train Loss: 0.881\n",
      "Epoch [30 / 30] \t Step [60 / 79] \t Train Loss: 0.807\n",
      "Epoch [30 / 30] \t Step [75 / 79] \t Train Loss: 0.978\n",
      "Epoch [30 / 30]:\n",
      "\ttrain BLEU: 54.82%\n",
      "\tval BLEU: 29.00%\n",
      "\n",
      "\n",
      "CPU times: user 4h 45min 1s, sys: 10min 27s, total: 4h 55min 29s\n",
      "Wall time: 13min 38s\n"
     ]
    }
   ],
   "source": [
    "    %%time\n",
    "    print_every = 15\n",
    "    num_epochs = 30\n",
    "    early_stopping_flag = True\n",
    "\n",
    "    lowest_val = 1e9\n",
    "    val_losses = []\n",
    "    total_step = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for step, (src, src_key_padding_mask, tgt, tgt_key_padding_mask) in enumerate(iter(loader)):\n",
    "            total_step += 1\n",
    "\n",
    "            src, src_key_padding_mask, tgt, tgt_key_padding_mask, memory_key_padding_mask, tgt_inp, tgt_out, tgt_mask = prep_transf_inputs2(\n",
    "                src, src_key_padding_mask, tgt, tgt_key_padding_mask, device)\n",
    "            \n",
    "            optim.zero_grad()\n",
    "            outputs = model(src, tgt_inp, src_key_padding_mask, tgt_key_padding_mask[:, :-1], memory_key_padding_mask, tgt_mask)\n",
    "            loss = criterion(rearrange(outputs, 'b t v -> (b t) v'), rearrange(tgt_out, 'b o -> (b o)'))\n",
    "\n",
    "            loss.backward()\n",
    "            optim.step_and_update_lr()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            if step % print_every == print_every - 1:\n",
    "                print(f'Epoch [{epoch + 1} / {num_epochs}] \\t Step [{step + 1} / {len(loader)}] \\t '\n",
    "                      'Train Loss: {:.3f}'.format(total_loss / print_every))\n",
    "                total_loss = 0\n",
    "                \n",
    "        if early_stopping_flag:\n",
    "            model.eval()\n",
    "            print(f'Epoch [{epoch + 1} / {num_epochs}]:')\n",
    "            print('{} BLEU: {:.2%}'.format(\n",
    "                '\\ttrain', get_bleu_from_loader2(model, loader)))\n",
    "            print('{} BLEU: {:.2%}'.format(\n",
    "                '\\tval', get_bleu_from_loader2(model, val_loader)))\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1 / 15] \t Step [15 / 79] \t Train Loss: 0.732\n",
      "Epoch [1 / 15] \t Step [30 / 79] \t Train Loss: 0.864\n",
      "Epoch [1 / 15] \t Step [45 / 79] \t Train Loss: 0.822\n",
      "Epoch [1 / 15] \t Step [60 / 79] \t Train Loss: 0.913\n",
      "Epoch [1 / 15] \t Step [75 / 79] \t Train Loss: 0.913\n",
      "Epoch [1 / 15]:\n",
      "\ttrain BLEU: 57.05%\n",
      "\tval BLEU: 29.41%\n",
      "\n",
      "\n",
      "Epoch [2 / 15] \t Step [15 / 79] \t Train Loss: 0.717\n",
      "Epoch [2 / 15] \t Step [30 / 79] \t Train Loss: 0.718\n",
      "Epoch [2 / 15] \t Step [45 / 79] \t Train Loss: 0.812\n",
      "Epoch [2 / 15] \t Step [60 / 79] \t Train Loss: 0.915\n",
      "Epoch [2 / 15] \t Step [75 / 79] \t Train Loss: 0.721\n",
      "Epoch [2 / 15]:\n",
      "\ttrain BLEU: 58.36%\n",
      "\tval BLEU: 29.18%\n",
      "\n",
      "\n",
      "Epoch [3 / 15] \t Step [15 / 79] \t Train Loss: 0.684\n",
      "Epoch [3 / 15] \t Step [30 / 79] \t Train Loss: 0.744\n",
      "Epoch [3 / 15] \t Step [45 / 79] \t Train Loss: 0.759\n",
      "Epoch [3 / 15] \t Step [60 / 79] \t Train Loss: 0.724\n",
      "Epoch [3 / 15] \t Step [75 / 79] \t Train Loss: 0.797\n",
      "Epoch [3 / 15]:\n",
      "\ttrain BLEU: 60.80%\n",
      "\tval BLEU: 29.72%\n",
      "\n",
      "\n",
      "Epoch [4 / 15] \t Step [15 / 79] \t Train Loss: 0.731\n",
      "Epoch [4 / 15] \t Step [30 / 79] \t Train Loss: 0.738\n",
      "Epoch [4 / 15] \t Step [45 / 79] \t Train Loss: 0.710\n",
      "Epoch [4 / 15] \t Step [60 / 79] \t Train Loss: 0.701\n",
      "Epoch [4 / 15] \t Step [75 / 79] \t Train Loss: 0.754\n",
      "Epoch [4 / 15]:\n",
      "\ttrain BLEU: 60.55%\n",
      "\tval BLEU: 29.12%\n",
      "\n",
      "\n",
      "Epoch [5 / 15] \t Step [15 / 79] \t Train Loss: 0.587\n",
      "Epoch [5 / 15] \t Step [30 / 79] \t Train Loss: 0.700\n",
      "Epoch [5 / 15] \t Step [45 / 79] \t Train Loss: 0.753\n",
      "Epoch [5 / 15] \t Step [60 / 79] \t Train Loss: 0.646\n",
      "Epoch [5 / 15] \t Step [75 / 79] \t Train Loss: 0.790\n",
      "Epoch [5 / 15]:\n",
      "\ttrain BLEU: 62.76%\n",
      "\tval BLEU: 29.73%\n",
      "\n",
      "\n",
      "Epoch [6 / 15] \t Step [15 / 79] \t Train Loss: 0.573\n",
      "Epoch [6 / 15] \t Step [30 / 79] \t Train Loss: 0.679\n",
      "Epoch [6 / 15] \t Step [45 / 79] \t Train Loss: 0.718\n",
      "Epoch [6 / 15] \t Step [60 / 79] \t Train Loss: 0.616\n",
      "Epoch [6 / 15] \t Step [75 / 79] \t Train Loss: 0.702\n",
      "Epoch [6 / 15]:\n",
      "\ttrain BLEU: 64.15%\n",
      "\tval BLEU: 29.85%\n",
      "\n",
      "\n",
      "Epoch [7 / 15] \t Step [15 / 79] \t Train Loss: 0.609\n",
      "Epoch [7 / 15] \t Step [30 / 79] \t Train Loss: 0.504\n",
      "Epoch [7 / 15] \t Step [45 / 79] \t Train Loss: 0.642\n",
      "Epoch [7 / 15] \t Step [60 / 79] \t Train Loss: 0.577\n",
      "Epoch [7 / 15] \t Step [75 / 79] \t Train Loss: 0.800\n",
      "Epoch [7 / 15]:\n",
      "\ttrain BLEU: 64.82%\n",
      "\tval BLEU: 29.57%\n",
      "\n",
      "\n",
      "Epoch [8 / 15] \t Step [15 / 79] \t Train Loss: 0.507\n",
      "Epoch [8 / 15] \t Step [30 / 79] \t Train Loss: 0.587\n",
      "Epoch [8 / 15] \t Step [45 / 79] \t Train Loss: 0.695\n",
      "Epoch [8 / 15] \t Step [60 / 79] \t Train Loss: 0.672\n",
      "Epoch [8 / 15] \t Step [75 / 79] \t Train Loss: 0.651\n",
      "Epoch [8 / 15]:\n",
      "\ttrain BLEU: 65.45%\n",
      "\tval BLEU: 29.18%\n",
      "\n",
      "\n",
      "Epoch [9 / 15] \t Step [15 / 79] \t Train Loss: 0.553\n",
      "Epoch [9 / 15] \t Step [30 / 79] \t Train Loss: 0.547\n",
      "Epoch [9 / 15] \t Step [45 / 79] \t Train Loss: 0.614\n",
      "Epoch [9 / 15] \t Step [60 / 79] \t Train Loss: 0.596\n",
      "Epoch [9 / 15] \t Step [75 / 79] \t Train Loss: 0.638\n",
      "Epoch [9 / 15]:\n",
      "\ttrain BLEU: 66.49%\n",
      "\tval BLEU: 29.41%\n",
      "\n",
      "\n",
      "Epoch [10 / 15] \t Step [15 / 79] \t Train Loss: 0.530\n",
      "Epoch [10 / 15] \t Step [30 / 79] \t Train Loss: 0.494\n",
      "Epoch [10 / 15] \t Step [45 / 79] \t Train Loss: 0.571\n",
      "Epoch [10 / 15] \t Step [60 / 79] \t Train Loss: 0.585\n",
      "Epoch [10 / 15] \t Step [75 / 79] \t Train Loss: 0.698\n",
      "Epoch [10 / 15]:\n",
      "\ttrain BLEU: 66.72%\n",
      "\tval BLEU: 29.00%\n",
      "\n",
      "\n",
      "Epoch [11 / 15] \t Step [15 / 79] \t Train Loss: 0.498\n",
      "Epoch [11 / 15] \t Step [30 / 79] \t Train Loss: 0.575\n",
      "Epoch [11 / 15] \t Step [45 / 79] \t Train Loss: 0.537\n",
      "Epoch [11 / 15] \t Step [60 / 79] \t Train Loss: 0.517\n",
      "Epoch [11 / 15] \t Step [75 / 79] \t Train Loss: 0.631\n",
      "Epoch [11 / 15]:\n",
      "\ttrain BLEU: 66.63%\n",
      "\tval BLEU: 29.04%\n",
      "\n",
      "\n",
      "Epoch [12 / 15] \t Step [15 / 79] \t Train Loss: 0.550\n",
      "Epoch [12 / 15] \t Step [30 / 79] \t Train Loss: 0.492\n",
      "Epoch [12 / 15] \t Step [45 / 79] \t Train Loss: 0.539\n",
      "Epoch [12 / 15] \t Step [60 / 79] \t Train Loss: 0.575\n",
      "Epoch [12 / 15] \t Step [75 / 79] \t Train Loss: 0.610\n",
      "Epoch [12 / 15]:\n",
      "\ttrain BLEU: 68.86%\n",
      "\tval BLEU: 29.06%\n",
      "\n",
      "\n",
      "Epoch [13 / 15] \t Step [15 / 79] \t Train Loss: 0.483\n",
      "Epoch [13 / 15] \t Step [30 / 79] \t Train Loss: 0.437\n",
      "Epoch [13 / 15] \t Step [45 / 79] \t Train Loss: 0.577\n",
      "Epoch [13 / 15] \t Step [60 / 79] \t Train Loss: 0.576\n",
      "Epoch [13 / 15] \t Step [75 / 79] \t Train Loss: 0.592\n",
      "Epoch [13 / 15]:\n",
      "\ttrain BLEU: 68.53%\n",
      "\tval BLEU: 29.37%\n",
      "\n",
      "\n",
      "Epoch [14 / 15] \t Step [15 / 79] \t Train Loss: 0.444\n",
      "Epoch [14 / 15] \t Step [30 / 79] \t Train Loss: 0.501\n",
      "Epoch [14 / 15] \t Step [45 / 79] \t Train Loss: 0.465\n",
      "Epoch [14 / 15] \t Step [60 / 79] \t Train Loss: 0.539\n",
      "Epoch [14 / 15] \t Step [75 / 79] \t Train Loss: 0.571\n",
      "Epoch [14 / 15]:\n",
      "\ttrain BLEU: 69.84%\n",
      "\tval BLEU: 29.51%\n",
      "\n",
      "\n",
      "Epoch [15 / 15] \t Step [15 / 79] \t Train Loss: 0.472\n",
      "Epoch [15 / 15] \t Step [30 / 79] \t Train Loss: 0.499\n",
      "Epoch [15 / 15] \t Step [45 / 79] \t Train Loss: 0.519\n",
      "Epoch [15 / 15] \t Step [60 / 79] \t Train Loss: 0.472\n",
      "Epoch [15 / 15] \t Step [75 / 79] \t Train Loss: 0.540\n",
      "Epoch [15 / 15]:\n",
      "\ttrain BLEU: 68.70%\n",
      "\tval BLEU: 29.26%\n",
      "\n",
      "\n",
      "CPU times: user 2h 21min 46s, sys: 5min 6s, total: 2h 26min 53s\n",
      "Wall time: 7min 42s\n"
     ]
    }
   ],
   "source": [
    "    %%time\n",
    "    print_every = 15\n",
    "    num_epochs = 15\n",
    "    early_stopping_flag = True\n",
    "\n",
    "    lowest_val = 1e9\n",
    "    val_losses = []\n",
    "    total_step = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for step, (src, src_key_padding_mask, tgt, tgt_key_padding_mask) in enumerate(iter(loader)):\n",
    "            total_step += 1\n",
    "\n",
    "            src, src_key_padding_mask, tgt, tgt_key_padding_mask, memory_key_padding_mask, tgt_inp, tgt_out, tgt_mask = prep_transf_inputs2(\n",
    "                src, src_key_padding_mask, tgt, tgt_key_padding_mask, device)\n",
    "            \n",
    "            optim.zero_grad()\n",
    "            outputs = model(src, tgt_inp, src_key_padding_mask, tgt_key_padding_mask[:, :-1], memory_key_padding_mask, tgt_mask)\n",
    "            loss = criterion(rearrange(outputs, 'b t v -> (b t) v'), rearrange(tgt_out, 'b o -> (b o)'))\n",
    "\n",
    "            loss.backward()\n",
    "            optim.step_and_update_lr()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            if step % print_every == print_every - 1:\n",
    "                print(f'Epoch [{epoch + 1} / {num_epochs}] \\t Step [{step + 1} / {len(loader)}] \\t '\n",
    "                      'Train Loss: {:.3f}'.format(total_loss / print_every))\n",
    "                total_loss = 0\n",
    "                \n",
    "        if early_stopping_flag:\n",
    "            model.eval()\n",
    "            print(f'Epoch [{epoch + 1} / {num_epochs}]:')\n",
    "            print('{} BLEU: {:.2%}'.format(\n",
    "                '\\ttrain', get_bleu_from_loader2(model, loader)))\n",
    "            print('{} BLEU: {:.2%}'.format(\n",
    "                '\\tval', get_bleu_from_loader2(model, val_loader)))\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# assess perf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "test_dataset = TagReportDataset(\n",
    "    os.path.join(data_path, 'tags/set_raw.pkl')\n",
    "    ,os.path.join(data_path, 'reports/set.pkl')\n",
    "    ,num_tokens\n",
    "    ,max_seq_length\n",
    "    ,idxs=splits['test']\n",
    "    ,countvec = countvec\n",
    ")\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True, num_workers=4, pin_memory=True)\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.5 s, sys: 1.32 s, total: 20.8 s\n",
      "Wall time: 906 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pred_list, tgt_list = infer(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test BLEU: 40.81%\n",
      "CPU times: user 1.58 s, sys: 20 ms, total: 1.6 s\n",
      "Wall time: 1.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pred_list_bleu, tgt_list_bleu = format_list_for_bleu(pred_list, tgt_list)\n",
    "print('{} BLEU: {:.2%}'.format(\n",
    "                'test', bleu_score(pred_list_bleu, tgt_list_bleu)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create vocab dicts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_index2word = dict(zip(range(len(dataset.countvec.vocabulary)), dataset.countvec.vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_translation.dataset import load_report_voc\n",
    "reports_index2word = load_report_voc(\n",
    "    os.path.join(data_path, 'reports', 'voc.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### assess nat lg perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsf_utils import print_nl_pred_vs_tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "k = 10\n",
    "sel_idx = random.sample(range(len(pred_list)), k=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET:   normal chest no evidence of tuberculosis heart size normal . lungs are clear . xxxx are normal . no pneumonia effusions edema pneumothorax adenopathy nodules or masses . .\n",
      "PREDICTION:  no chest heart evidence of tuberculosis heart size normal . lungs are clear . xxxx are normal . no pneumonia effusions edema pneumothorax adenopathy nodules or masses . .\n",
      "\n",
      "\n",
      "TARGET:   no acute cardiopulmonary abnormality . mediastinal contours are normal . heart size is within normal limits . multiple scattered calcified pulmonary nodules xxxx sequela of prior granulomatous disease . otherwise lungs are clear . . there is no pneumothorax or large pleural effusion . no bony abnormality . .\n",
      "PREDICTION:   acute cardiopulmonary abnormality . . contours are within . no size is within normal limits . no calcified calcified granulomas nodules are . of prior granulomatous disease . no lungs are clear without no no is no pneumothorax or large pleural effusion . there acute abnormality . .\n",
      "\n",
      "\n",
      "TARGET:   no acute findings . cardiac and mediastinal contours are within normal limits . the lungs are clear . bony structures are intact . .\n",
      "PREDICTION:  no acute cardiopulmonary . cardiac and mediastinal contours are within normal limits . the lungs are clear . bony structures are intact . .\n",
      "\n",
      "\n",
      "TARGET:   exam quality limited by hypoinflation and rotation . considering technical factors heart size xxxx mildly enlarged aortic calcifications and ectasia tortuosity mediastinal calcifications suggest a previous granulomatous process . no focal alveolar consolidation no definite pleural effusion seen . bronchovascular crowding without typical findings of pulmonary edema . .\n",
      "PREDICTION:   quality limited by body and no . heart technical factors xxxx size and within enlarged . ectasia and aortic tortuosity stable contours suggest a previous granulomatous process . no focal alveolar consolidation no definite pleural effusion seen . no crowding without typical findings of pulmonary edema . .\n",
      "\n",
      "\n",
      "TARGET:   no acute cardiopulmonary disease . . the cardiomediastinal silhouette is normal size and configuration . pulmonary vasculature within normal limits . the lungs are well aerated . there is no pneumothorax pleural effusion or focal consolidation . .\n",
      "PREDICTION:  no acute cardiopulmonary abnormality . the the cardiomediastinal silhouette is normal in and configuration . pulmonary vasculature within normal limits . the lungs are well aerated . there is no pneumothorax pleural effusion or focal consolidation . bony\n",
      "\n",
      "\n",
      "TARGET:   copd . no acute pulmonary disease . there is hyperinflation of the lungs appear to be clear . there is no pleural effusion or the heart is normal . there are atherosclerotic changes of the aorta . the skeletal structures are normal . .\n",
      "PREDICTION:   . no acute pulmonary disease . the is a . the lungs . to be clear . there is no pleural effusion or pneumothorax heart and not in arthritic are no changes of the aorta . arthritic skeletal structures are normal . .\n",
      "\n",
      "\n",
      "TARGET:   low lung volumes otherwise clear . the cardiomediastinal silhouette is normal in size and contour . no focal consolidation pneumothorax or large pleural effusion . normal xxxx . xxxx cholecystectomy . .\n",
      "PREDICTION:  no lung volumes with no . the cardiomediastinal silhouette is normal in size and contour . no focal consolidation pneumothorax or large pleural effusion . calcified xxxx . . foreign . .\n",
      "\n",
      "\n",
      "TARGET:   minimal xxxx left base atelectasis infiltrate . otherwise stable exam . mild cardiomegaly unchanged . stable superior mediastinal contour with tortuous aorta . normal pulmonary vascularity . unchanged elevated right hemidiaphragm with minimal right base subsegmental atelectasis . minimal xxxx left basal airspace opacity . unchanged blunting of the right lateral costophrenic xxxx scarring versus xxxx effusion . no pneumothorax . no acute osseous findings . .\n",
      "PREDICTION:   left right basilar airspace . . the unremarkable appearance . stable cardiomegaly . . the cardiomegaly mediastinal contour . unchanged aorta . no pulmonary vascularity . no right right hemidiaphragm . xxxx right pleural atelectasis atelectasis or no right right pleural airspace disease . no blunting of the right costophrenic costophrenic xxxx . . atelectasis . . no pneumothorax or no acute bony findings . .\n",
      "\n",
      "\n",
      "TARGET:   mild cardiomegaly no acute pulmonary findings mild cardiomegaly stable mediastinal contours . no focal alveolar consolidation no definite pleural effusion seen . mild bronchovascular crowding without typical findings of pulmonary edema . .\n",
      "PREDICTION:  cardiomegaly cardiomegaly . acute pulmonary findings heart cardiomegaly . mediastinal contours . stable focal alveolar consolidation no definite pleural effusion seen . no right crowding without typical findings of pulmonary edema . .\n",
      "\n",
      "\n",
      "TARGET:   mild blunted right costophrenic xxxx which could be due to xxxx effusion or scarring . the heart and mediastinum are normal . the lungs are clear . there is mild blunting of the right costophrenic xxxx . there is no infiltrate mass or pneumothorax . the right internal jugular catheter has been removed . .\n",
      "PREDICTION:   bibasilar left costophrenic xxxx . may represent secondary to atelectasis effusion or atelectasis . no cardiomediastinal size mediastinum are within . the lungs are clear . there is no xxxx of the costophrenic costophrenic xxxx . there is no pneumothorax or or pneumothorax . . bony costophrenic jugular catheter has been removed . .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_nl_pred_vs_tgt(\n",
    "                [pred_list[i] for i in sel_idx]\n",
    "                ,[tgt_list[i] for i in sel_idx]\n",
    "                ,reports_index2word\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
