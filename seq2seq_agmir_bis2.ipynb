{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "import string\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r'/home/alex/data/nlp/agmir/toy_data/trs_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loaders import prepareReportData, normalizeString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read data...\n",
      "read 3580 reports\n",
      "trimmed to 3580 sentence pairs\n",
      "counting words...\n",
      "counted words:\n",
      "\t tags 590\n",
      "\t report 1953\n"
     ]
    }
   ],
   "source": [
    "input_lang, output_lang, ds = prepareReportData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# more processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loaders import EOS_token, SOS_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)[:MAX_LENGTH]\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[2],\n",
       "         [1]], device='cuda:0'),\n",
       " tensor([[  2],\n",
       "         [  3],\n",
       "         [  9],\n",
       "         [ 10],\n",
       "         [ 11],\n",
       "         [169],\n",
       "         [  3],\n",
       "         [  3],\n",
       "         [ 41],\n",
       "         [ 94],\n",
       "         [ 95],\n",
       "         [ 25],\n",
       "         [ 20],\n",
       "         [ 21],\n",
       "         [ 22],\n",
       "         [175],\n",
       "         [164],\n",
       "         [  3],\n",
       "         [ 41],\n",
       "         [286],\n",
       "         [ 25],\n",
       "         [287],\n",
       "         [  3],\n",
       "         [  9],\n",
       "         [ 27],\n",
       "         [ 23],\n",
       "         [ 29],\n",
       "         [  3],\n",
       "         [  9],\n",
       "         [ 37]], device='cuda:0'))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_pair = ds.__getitem__(100)[:2]\n",
    "tensorsFromPair((report_pair[0], normalizeString(report_pair[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import asMinutes, timeSince"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    \n",
    "    training_pairs = []\n",
    "    for i in range(n_iters):\n",
    "        report_id = random.choice(range(len(ds)))\n",
    "        report_pair = ds.__getitem__(report_id)[:2]\n",
    "        report_pair = (report_pair[0], normalizeString(report_pair[1]))\n",
    "        #print(report_pair)\n",
    "        training_pairs.append(tensorsFromPair(report_pair))   \n",
    "    \n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eval routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can evaluate random sentences from the training set and print out the\n",
    "input, target, and output to make some subjective quality judgements:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    tuples = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        report_id = random.choice(range(len(ds)))\n",
    "        report_pair = ds.__getitem__(report_id)[:2]\n",
    "        pair = (report_pair[0], normalizeString(report_pair[1]))\n",
    "        \n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')\n",
    "        tuples.append((pair[0], pair[1], output_sentence))\n",
    "        \n",
    "    return tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateAll(encoder, decoder):\n",
    "    tuples = [] \n",
    "    \n",
    "    for report_id in range(len(ds)):\n",
    "        # get+process pair\n",
    "        report_pair = ds.__getitem__(report_id)[:2]\n",
    "        pair = (report_pair[0], normalizeString(report_pair[1]))\n",
    "        \n",
    "        # perform inference\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        tuples.append((pair[0], pair[1], output_sentence))\n",
    "        \n",
    "    return tuples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import EncoderRNN, AttnDecoderRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 45s (- 85m 49s) (1000 2%) 4.3096\n",
      "3m 19s (- 79m 57s) (2000 4%) 3.7561\n",
      "4m 52s (- 76m 25s) (3000 6%) 3.6704\n",
      "6m 20s (- 72m 50s) (4000 8%) 3.4716\n",
      "7m 30s (- 67m 34s) (5000 10%) 3.5152\n",
      "9m 3s (- 66m 23s) (6000 12%) 3.3609\n",
      "10m 32s (- 64m 45s) (7000 14%) 3.2244\n",
      "12m 1s (- 63m 6s) (8000 16%) 3.2900\n",
      "13m 40s (- 62m 17s) (9000 18%) 3.2125\n",
      "15m 13s (- 60m 52s) (10000 20%) 3.1200\n",
      "16m 44s (- 59m 19s) (11000 22%) 3.2109\n",
      "18m 15s (- 57m 49s) (12000 24%) 3.1770\n",
      "19m 44s (- 56m 12s) (13000 26%) 3.1901\n",
      "21m 20s (- 54m 53s) (14000 28%) 3.1033\n",
      "22m 58s (- 53m 35s) (15000 30%) 3.0824\n",
      "24m 30s (- 52m 5s) (16000 32%) 3.0624\n",
      "26m 8s (- 50m 44s) (17000 34%) 3.0094\n",
      "27m 42s (- 49m 16s) (18000 36%) 3.0398\n",
      "29m 20s (- 47m 52s) (19000 38%) 2.9709\n",
      "30m 53s (- 46m 19s) (20000 40%) 3.1022\n",
      "32m 23s (- 44m 44s) (21000 42%) 2.9324\n",
      "33m 59s (- 43m 15s) (22000 44%) 2.9677\n",
      "35m 24s (- 41m 34s) (23000 46%) 2.9266\n",
      "36m 52s (- 39m 56s) (24000 48%) 3.0072\n",
      "38m 22s (- 38m 22s) (25000 50%) 2.9921\n",
      "39m 49s (- 36m 45s) (26000 52%) 2.9128\n",
      "41m 12s (- 35m 6s) (27000 54%) 2.9514\n",
      "42m 35s (- 33m 28s) (28000 56%) 2.9588\n",
      "43m 52s (- 31m 45s) (29000 57%) 2.9002\n",
      "45m 7s (- 30m 4s) (30000 60%) 2.9002\n",
      "46m 28s (- 28m 28s) (31000 62%) 2.8916\n",
      "48m 2s (- 27m 1s) (32000 64%) 2.8921\n",
      "49m 26s (- 25m 28s) (33000 66%) 2.8478\n",
      "50m 34s (- 23m 48s) (34000 68%) 2.9084\n",
      "52m 2s (- 22m 18s) (35000 70%) 2.7847\n",
      "53m 23s (- 20m 45s) (36000 72%) 2.8743\n",
      "54m 32s (- 19m 9s) (37000 74%) 2.8849\n",
      "55m 38s (- 17m 34s) (38000 76%) 2.8127\n",
      "56m 45s (- 16m 0s) (39000 78%) 2.7912\n",
      "57m 57s (- 14m 29s) (40000 80%) 2.7605\n",
      "59m 17s (- 13m 0s) (41000 82%) 2.7619\n",
      "60m 38s (- 11m 32s) (42000 84%) 2.7525\n",
      "61m 49s (- 10m 3s) (43000 86%) 2.7342\n",
      "63m 5s (- 8m 36s) (44000 88%) 2.7862\n",
      "64m 38s (- 7m 10s) (45000 90%) 2.7117\n",
      "66m 15s (- 5m 45s) (46000 92%) 2.7441\n",
      "67m 47s (- 4m 19s) (47000 94%) 2.8011\n",
      "69m 19s (- 2m 53s) (48000 96%) 2.7588\n",
      "70m 56s (- 1m 26s) (49000 98%) 2.8197\n",
      "72m 22s (- 0m 0s) (50000 100%) 2.7753\n",
      "CPU times: user 1h 11min 41s, sys: 41.3 s, total: 1h 12min 22s\n",
      "Wall time: 1h 12min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, max_length=MAX_LENGTH, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 50000, print_every=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from perf import get_av_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_output = evaluateAll(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08513800782339259"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_av_bleu(pred_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
